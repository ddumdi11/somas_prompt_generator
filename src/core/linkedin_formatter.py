"""LinkedIn-Formatter fÃ¼r Unicode-basierte Textformatierung.

LinkedIn unterstÃ¼tzt kein Markdown, aber Unicode-Zeichen fÃ¼r Fett/Kursiv.
"""

import re

# Unicode Bold (Sans-Serif Bold)
UNICODE_BOLD = {
    'A': 'ğ—”', 'B': 'ğ—•', 'C': 'ğ—–', 'D': 'ğ——', 'E': 'ğ—˜', 'F': 'ğ—™', 'G': 'ğ—š',
    'H': 'ğ—›', 'I': 'ğ—œ', 'J': 'ğ—', 'K': 'ğ—', 'L': 'ğ—Ÿ', 'M': 'ğ— ', 'N': 'ğ—¡',
    'O': 'ğ—¢', 'P': 'ğ—£', 'Q': 'ğ—¤', 'R': 'ğ—¥', 'S': 'ğ—¦', 'T': 'ğ—§', 'U': 'ğ—¨',
    'V': 'ğ—©', 'W': 'ğ—ª', 'X': 'ğ—«', 'Y': 'ğ—¬', 'Z': 'ğ—­',
    'a': 'ğ—®', 'b': 'ğ—¯', 'c': 'ğ—°', 'd': 'ğ—±', 'e': 'ğ—²', 'f': 'ğ—³', 'g': 'ğ—´',
    'h': 'ğ—µ', 'i': 'ğ—¶', 'j': 'ğ—·', 'k': 'ğ—¸', 'l': 'ğ—¹', 'm': 'ğ—º', 'n': 'ğ—»',
    'o': 'ğ—¼', 'p': 'ğ—½', 'q': 'ğ—¾', 'r': 'ğ—¿', 's': 'ğ˜€', 't': 'ğ˜', 'u': 'ğ˜‚',
    'v': 'ğ˜ƒ', 'w': 'ğ˜„', 'x': 'ğ˜…', 'y': 'ğ˜†', 'z': 'ğ˜‡',
    '0': 'ğŸ¬', '1': 'ğŸ­', '2': 'ğŸ®', '3': 'ğŸ¯', '4': 'ğŸ°',
    '5': 'ğŸ±', '6': 'ğŸ²', '7': 'ğŸ³', '8': 'ğŸ´', '9': 'ğŸµ',
    # Umlaute haben keine Unicode-Bold-Varianten, bleiben normal
}

# Unicode Italic (Sans-Serif Italic)
UNICODE_ITALIC = {
    'A': 'ğ˜ˆ', 'B': 'ğ˜‰', 'C': 'ğ˜Š', 'D': 'ğ˜‹', 'E': 'ğ˜Œ', 'F': 'ğ˜', 'G': 'ğ˜',
    'H': 'ğ˜', 'I': 'ğ˜', 'J': 'ğ˜‘', 'K': 'ğ˜’', 'L': 'ğ˜“', 'M': 'ğ˜”', 'N': 'ğ˜•',
    'O': 'ğ˜–', 'P': 'ğ˜—', 'Q': 'ğ˜˜', 'R': 'ğ˜™', 'S': 'ğ˜š', 'T': 'ğ˜›', 'U': 'ğ˜œ',
    'V': 'ğ˜', 'W': 'ğ˜', 'X': 'ğ˜Ÿ', 'Y': 'ğ˜ ', 'Z': 'ğ˜¡',
    'a': 'ğ˜¢', 'b': 'ğ˜£', 'c': 'ğ˜¤', 'd': 'ğ˜¥', 'e': 'ğ˜¦', 'f': 'ğ˜§', 'g': 'ğ˜¨',
    'h': 'ğ˜©', 'i': 'ğ˜ª', 'j': 'ğ˜«', 'k': 'ğ˜¬', 'l': 'ğ˜­', 'm': 'ğ˜®', 'n': 'ğ˜¯',
    'o': 'ğ˜°', 'p': 'ğ˜±', 'q': 'ğ˜²', 'r': 'ğ˜³', 's': 'ğ˜´', 't': 'ğ˜µ', 'u': 'ğ˜¶',
    'v': 'ğ˜·', 'w': 'ğ˜¸', 'x': 'ğ˜¹', 'y': 'ğ˜º', 'z': 'ğ˜»',
    # Umlaute haben keine Unicode-Italic-Varianten, bleiben normal
}


def to_bold(text: str) -> str:
    """Konvertiert Text zu Unicode Bold.

    Args:
        text: Eingabetext

    Returns:
        Text mit Unicode Bold-Zeichen
    """
    return ''.join(UNICODE_BOLD.get(c, c) for c in text)


def to_italic(text: str) -> str:
    """Konvertiert Text zu Unicode Italic.

    Args:
        text: Eingabetext

    Returns:
        Text mit Unicode Italic-Zeichen
    """
    return ''.join(UNICODE_ITALIC.get(c, c) for c in text)


def create_post_header(title: str, channel: str) -> str:
    """Erstellt den LinkedIn-Post-Header aus Video-Metadaten.

    Format:
        ğ—©ğ—¶ğ—±ğ—²ğ—¼-ğ—§ğ—¶ğ˜ğ—²ğ—¹ (fett)
        Kanal, YT

        ğ—¦ğ—¢ğ— ğ—”ğ—¦-ğ—”ğ—»ğ—®ğ—¹ğ˜†ğ˜€ğ—² (fett)

    Args:
        title: Video-Titel
        channel: Kanal-Name

    Returns:
        Formatierter Header fÃ¼r LinkedIn-Post
    """
    bold_title = to_bold(title)
    bold_somas = to_bold("SOMAS-Analyse")
    return f"{bold_title}\n{channel}, YT\n\n{bold_somas}\n\n"


def extract_analysis_body(text: str) -> str:
    """Extrahiert den Analyse-Text ab FRAMING (ohne Einleitung).

    Args:
        text: VollstÃ¤ndiger Analyse-Text

    Returns:
        Text ab FRAMING (ohne EinleitungssÃ¤tze)
    """
    # Suche nach FRAMING (mit oder ohne ### Markdown-Header)
    framing_patterns = [
        r'(?m)^###?\s*FRAMING',  # ### FRAMING oder # FRAMING
        r'(?m)^FRAMING',          # FRAMING ohne Markdown
        r'(?m)^ğ—™ğ—¥ğ—”ğ— ğ—œğ—¡ğ—š',        # Bereits konvertiertes Unicode-Bold
    ]

    for pattern in framing_patterns:
        match = re.search(pattern, text)
        if match:
            return text[match.start():]

    # Falls kein FRAMING gefunden, gib den ganzen Text zurÃ¼ck
    return text


def strip_url_protocol(url: str) -> str:
    """Entfernt Protokoll und www. von einer URL.

    Args:
        url: VollstÃ¤ndige URL

    Returns:
        URL ohne https://, http:// und www.
    """
    url = re.sub(r'^https?://', '', url)
    url = re.sub(r'^www\.', '', url)
    return url


def extract_domain_name(url: str) -> str:
    """Extrahiert den Domain-Namen ohne Protokoll, www und TLD.

    Args:
        url: VollstÃ¤ndige URL oder Domain

    Returns:
        Reiner Domain-Name (z.B. 'timesofisrael', 'cnn')
    """
    domain = strip_url_protocol(url).split('/')[0]
    # TLD entfernen (.com, .org, .net, .de, etc.)
    domain = re.sub(r'\.[a-z]{2,}$', '', domain)
    return domain


# Unicode Superscript-Ziffern fÃ¼r FuÃŸnoten
SUPERSCRIPT_DIGITS = {
    '0': '\u2070', '1': '\u00b9', '2': '\u00b2', '3': '\u00b3',
    '4': '\u2074', '5': '\u2075', '6': '\u2076', '7': '\u2077',
    '8': '\u2078', '9': '\u2079',
}


def to_superscript(number: int) -> str:
    """Konvertiert eine Zahl zu Unicode-Superscript.

    Args:
        number: FuÃŸnoten-Nummer

    Returns:
        Unicode-Superscript-Darstellung (z.B. 1 â†’ Â¹, 12 â†’ Â¹Â²)
    """
    return ''.join(SUPERSCRIPT_DIGITS[d] for d in str(number))


def format_for_linkedin(text: str, video_title: str = "", video_channel: str = "") -> str:
    """Konvertiert Markdown-formatierten Text zu LinkedIn-kompatiblem Format.

    Transformationen:
    - Extrahiert nur den Analyse-Teil (ab FRAMING)
    - ### HEADING â†’ entfernt (ZwischenÃ¼berschriften werden zu Leerzeilen)
    - **bold** â†’ ğ—¯ğ—¼ğ—¹ğ—±
    - *italic* oder _italic_ â†’ ğ˜ªğ˜µğ˜¢ğ˜­ğ˜ªğ˜¤
    - - item â†’ â€¢ item
    - URLs aus FlieÃŸtext entfernen, am Ende als Quellenblock sammeln

    Args:
        text: Markdown-formatierter Text
        video_title: Optional - Video-Titel fÃ¼r Post-Header
        video_channel: Optional - Kanal-Name fÃ¼r Post-Header

    Returns:
        LinkedIn-kompatibler Text mit Unicode-Formatierung
    """
    # Nur den Analyse-Teil ab FRAMING extrahieren (ohne Einleitung)
    analysis_text = extract_analysis_body(text)

    lines = analysis_text.split('\n')
    result_lines: list[str] = []
    collected_sources: list[tuple[int, str, str]] = []  # (nummer, name, domain)
    footnote_counter = 0

    # SOMAS-AbschnittsÃ¼berschriften (mit und ohne Markdown-Hashes)
    somas_headers = [
        'FRAMING', 'KERNTHESE', 'ELABORATION', 'IMPLIKATION',
        'KRITIK', 'OFFENE_FRAGEN', 'ZITATE', 'VERBINDUNGEN',
        'ANSCHLUSSFRAGE', 'QUICK INFO'
    ]
    somas_pattern = r'^(?:#{1,6}\s+)?(' + '|'.join(somas_headers) + r')(?:\s*:?)?\s*$'

    for line in lines:
        # SOMAS-Ãœberschriften â†’ Leerzeile (Abschnitt visuell trennen)
        if re.match(somas_pattern, line.strip(), re.IGNORECASE):
            # FÃ¼ge Leerzeile als Trenner hinzu (falls nicht am Anfang)
            if result_lines and result_lines[-1].strip():
                result_lines.append('')
            continue

        # Andere Markdown-Headers: ### HEADING â†’ auch entfernen
        header_match = re.match(r'^(#{1,6})\s+(.+)$', line)
        if header_match:
            if result_lines and result_lines[-1].strip():
                result_lines.append('')
            continue

        # SOMAS-Header am Zeilenanfang entfernen (auch mit nachfolgendem Text)
        for header in somas_headers:
            line = re.sub(rf'^{header}\s*:\s*', '', line, flags=re.IGNORECASE)

        # Markdown Links: [text](url) â†’ Text [N]
        def collect_markdown_link(match):
            nonlocal footnote_counter
            name = match.group(1)
            url = match.group(2)
            footnote_counter += 1
            domain = extract_domain_name(url)
            collected_sources.append((footnote_counter, name, domain))
            return f"{name} [{footnote_counter}]"
        line = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', collect_markdown_link, line)

        # Bare URLs im Text: durch [N] ersetzen
        def collect_bare_url(match):
            nonlocal footnote_counter
            url = match.group(0)
            domain = extract_domain_name(url)
            footnote_counter += 1
            collected_sources.append((footnote_counter, domain, domain))
            return f"[{footnote_counter}]"
        line = re.sub(r'https?://[^\s,)]+', collect_bare_url, line)

        # Code blocks: `code` â†’ code (einfach Backticks entfernen)
        line = re.sub(r'`([^`]+)`', r'\1', line)

        # Bold: **text** â†’ Unicode Bold
        def bold_replace(match):
            return to_bold(match.group(1))
        line = re.sub(r'\*\*([^*]+)\*\*', bold_replace, line)

        # Italic: *text* oder _text_ â†’ Unicode Italic
        def italic_replace(match):
            return to_italic(match.group(1))
        line = re.sub(r'(?<!\*)\*([^*]+)\*(?!\*)', italic_replace, line)
        line = re.sub(r'_([^_]+)_', italic_replace, line)

        # Bullet points: - item â†’ â€¢ item
        line = re.sub(r'^(\s*)-\s+', r'\1â€¢ ', line)

        result_lines.append(line)

    formatted_text = '\n'.join(result_lines)

    # Mehrfache Leerzeilen auf eine reduzieren
    formatted_text = re.sub(r'\n{3,}', '\n\n', formatted_text)

    # FÃ¼hrende/trailing Leerzeilen entfernen
    formatted_text = formatted_text.strip()

    # Post-Header hinzufÃ¼gen, wenn Video-Infos vorhanden
    if video_title and video_channel:
        header = create_post_header(video_title, video_channel)
        formatted_text = header + formatted_text

    # Domain-Namen vor [N]-Markern entfernen (AI gibt oft "domainname URL" aus)
    if collected_sources:
        for _, _, domain in collected_sources:
            # "domainname [N]" â†’ "[N]" und "domainname. [N]" â†’ "[N]"
            formatted_text = re.sub(
                rf'\b{re.escape(domain)}\.?\s*(\[\d+\])',
                r'\1',
                formatted_text,
                flags=re.IGNORECASE
            )

    # Quellenblock am Ende: gleiche Domains zusammenfassen
    if collected_sources:
        # Gruppiere FuÃŸnoten-Nummern nach Domain
        domain_numbers: dict[str, list[int]] = {}
        for number, name, domain in collected_sources:
            if domain not in domain_numbers:
                domain_numbers[domain] = []
            domain_numbers[domain].append(number)

        # Formatiere: "1,6: timesofisrael" oder "2: cnn"
        source_parts: list[str] = []
        for domain, numbers in domain_numbers.items():
            nums = ",".join(str(n) for n in numbers)
            source_parts.append(f"{nums}: {domain}")

        formatted_text += "\n\nQuellen: " + " | ".join(source_parts)

    return formatted_text
