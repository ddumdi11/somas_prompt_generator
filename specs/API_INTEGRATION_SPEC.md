# API-Integration f√ºr SOMAS Prompt Generator

> **Entwicklungsanweisung f√ºr Claude Code ‚Äì Phase 3: API-Automatisierung**
>
> Erstellt von: Claude.ai (Architekt)  
> F√ºr: Claude Code (Implementierung)  
> Supervisor: Thorsten

---

## üéØ Ziel dieser Phase

Der SOMAS Prompt Generator soll um **automatische LLM-API-Aufrufe** erweitert werden. Der Nutzer kann optional ein Modell ausw√§hlen, und der generierte Prompt wird automatisch an die API gesendet. Das Ergebnis erscheint direkt im Analyse-Ergebnis-Feld.

**Wichtig:** Der manuelle Workflow (Copy Prompt ‚Üí Paste Result) bleibt vollst√§ndig erhalten!

---

## üìã Anforderungen

### Funktionale Anforderungen

1. **API-Modus Toggle**
   - Checkbox oder Toggle: "API-Automatik aktivieren"
   - Wenn aktiv: Nach "Generate Prompt" wird automatisch der API-Call getriggert
   - Wenn inaktiv: Verhalten wie bisher (manueller Copy/Paste-Workflow)

2. **Provider-/Modell-Auswahl**
   - Dropdown f√ºr Provider (Perplexity, OpenRouter, ...)
   - Dropdown f√ºr Modell (dynamisch basierend auf Provider)
   - Modell-Liste soll **dynamisch von der API abgerufen** werden
   - Zuletzt gew√§hltes Modell als Default speichern

3. **Status-Anzeige**
   - Visuelle Anzeige des API-Status:
     - üîµ **Sending** ‚Äì Request wird gesendet
     - üü° **Processing** ‚Äì Warte auf Antwort
     - üü¢ **Received** ‚Äì Antwort erfolgreich empfangen
     - üî¥ **Error** ‚Äì Fehler aufgetreten (mit Fehlermeldung)
   - Position: Neben dem Analyse-Ergebnis-Feld oder als separate Statuszeile

4. **Settings-Dialog**
   - Aufruf √ºber Zahnrad-Symbol (‚öôÔ∏è) neben dem Modell-Dropdown
   - Inhalte:
     - API-Keys verwalten (hinzuf√ºgen, √§ndern, l√∂schen)
     - Provider aktivieren/deaktivieren
     - Default-Modell festlegen
   - API-Keys werden **verschl√ºsselt** gespeichert (siehe unten)

5. **LinkedIn-Export-Header**
   - Nach API-Nutzung: Modell + Provider im Header anzeigen
   - Format: `SOMAS-Analyse (von [Modell], [Provider])`
   - Beispiel: `SOMAS-Analyse (von Gemini 3 Pro, Perplexity)`

### Nicht-funktionale Anforderungen

- **Non-blocking UI**: API-Calls in separatem Thread (QThread)
- **Sichere Key-Speicherung**: √úber `keyring` Bibliothek (OS-native Credential Manager)
- **Portabilit√§t**: Nicht-sensitive Config in JSON-Datei (kopierbar)
- **Graceful Degradation**: App funktioniert auch ohne konfigurierte API

---

## üèóÔ∏è Architektur

### Neue Dateien

```
src/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ api_client.py          # Abstrakte Basis-Klasse f√ºr LLM-Clients
‚îÇ   ‚îú‚îÄ‚îÄ perplexity_client.py   # Perplexity-Implementation
‚îÇ   ‚îú‚îÄ‚îÄ openrouter_client.py   # OpenRouter-Implementation (optional, sp√§ter)
‚îÇ   ‚îî‚îÄ‚îÄ api_worker.py          # QThread-Worker f√ºr async API-Calls
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ api_config.py          # API-Konfiguration laden/speichern
‚îÇ   ‚îî‚îÄ‚îÄ api_providers.json     # Provider-Definitionen (nicht Keys!)
‚îÇ
‚îî‚îÄ‚îÄ gui/
    ‚îú‚îÄ‚îÄ main_window.py         # Erweitern um API-Sektion
    ‚îî‚îÄ‚îÄ settings_dialog.py     # NEU: Settings-Dialog f√ºr API-Keys
```

### Datenmodelle

```python
# src/config/api_config.py
from dataclasses import dataclass
from enum import Enum

class APIStatus(Enum):
    IDLE = "idle"
    SENDING = "sending"
    PROCESSING = "processing"
    RECEIVED = "received"
    ERROR = "error"

@dataclass
class APIProvider:
    id: str                    # z.B. "perplexity"
    name: str                  # z.B. "Perplexity AI"
    base_url: str              # z.B. "https://api.perplexity.ai"
    models_endpoint: str       # z.B. "/models" (f√ºr dynamische Liste)
    chat_endpoint: str         # z.B. "/chat/completions"
    requires_online: bool      # Perplexity: True (Web-Search)

@dataclass
class APIResponse:
    status: APIStatus
    content: str = ""
    error_message: str = ""
    model_used: str = ""
    provider_used: str = ""
    tokens_used: int = 0
```

---

## üîê Sichere Key-Speicherung

### Bibliothek: `keyring`

```python
import keyring

SERVICE_NAME = "somas_prompt_generator"

def save_api_key(provider_id: str, api_key: str) -> None:
    """Speichert API-Key sicher im OS Credential Manager."""
    keyring.set_password(SERVICE_NAME, f"{provider_id}_api_key", api_key)

def get_api_key(provider_id: str) -> str | None:
    """Holt API-Key aus dem OS Credential Manager."""
    return keyring.get_password(SERVICE_NAME, f"{provider_id}_api_key")

def delete_api_key(provider_id: str) -> None:
    """L√∂scht API-Key aus dem OS Credential Manager."""
    try:
        keyring.delete_password(SERVICE_NAME, f"{provider_id}_api_key")
    except keyring.errors.PasswordDeleteError:
        pass  # Key existierte nicht
```

### Was wird WO gespeichert?

| Daten | Speicherort | Verschl√ºsselt? |
|-------|-------------|----------------|
| API-Keys | OS Credential Manager (keyring) | ‚úÖ Ja (OS-level) |
| Provider-Definitionen | `api_providers.json` | ‚ùå Nein (√∂ffentlich) |
| Zuletzt gew√§hltes Modell | `user_preferences.json` | ‚ùå Nein |
| Cached Modell-Listen | In-Memory (Session) | ‚Äì |

---

## üîÑ Threading f√ºr Non-Blocking UI

```python
# src/core/api_worker.py
from PyQt6.QtCore import QThread, pyqtSignal
from .api_client import LLMClient, APIResponse, APIStatus

class APIWorker(QThread):
    """Worker-Thread f√ºr API-Aufrufe ohne UI-Blockierung."""
    
    status_changed = pyqtSignal(str)      # "sending", "processing", "received", "error"
    response_received = pyqtSignal(object)  # APIResponse-Objekt
    error_occurred = pyqtSignal(str)       # Fehlermeldung
    
    def __init__(self, client: LLMClient, prompt: str, model: str):
        super().__init__()
        self.client = client
        self.prompt = prompt
        self.model = model
    
    def run(self):
        self.status_changed.emit("sending")
        try:
            # Hier k√∂nnte man "processing" emittieren wenn die API
            # Streaming unterst√ºtzt und der erste Chunk kommt
            self.status_changed.emit("processing")
            
            response = self.client.send_prompt(self.prompt, self.model)
            
            if response.status == APIStatus.RECEIVED:
                self.status_changed.emit("received")
                self.response_received.emit(response)
            else:
                self.status_changed.emit("error")
                self.error_occurred.emit(response.error_message)
                
        except Exception as e:
            self.status_changed.emit("error")
            self.error_occurred.emit(str(e))
```

---

## üåê Perplexity API Client

### Endpoint-Dokumentation

- **Base URL:** `https://api.perplexity.ai`
- **Chat Completions:** `POST /chat/completions`
- **Models:** Leider keine `/models` Endpoint ‚Äì Liste muss hardcoded werden

### Verf√ºgbare Modelle (Stand Januar 2026)

```python
PERPLEXITY_MODELS = [
    # Aktuelle Modellnamen (vereinfacht seit 2025)
    "sonar",           # Balanced - Geschwindigkeit & Kosten
    "sonar-pro",       # Best f√ºr komplexe Queries (ehem. huge/large)
    "sonar-reasoning", # Spezialisiert f√ºr Reasoning-Tasks
]
```

**Hinweis f√ºr Pro-User:** $5 monatliches API-Guthaben inklusive (verf√§llt am Monatsende).

### Implementation

```python
# src/core/perplexity_client.py
import requests
from .api_client import LLMClient, APIResponse, APIStatus

class PerplexityClient(LLMClient):
    """Perplexity AI API Client."""
    
    BASE_URL = "https://api.perplexity.ai"
    PROVIDER_ID = "perplexity"
    PROVIDER_NAME = "Perplexity AI"
    
    # Aktuelle Modellnamen (Stand Januar 2026)
    MODELS = [
        {"id": "sonar", "name": "Sonar", "description": "Balanced - Geschwindigkeit & Kosten"},
        {"id": "sonar-pro", "name": "Sonar Pro", "description": "Best f√ºr komplexe Queries"},
        {"id": "sonar-reasoning", "name": "Sonar Reasoning", "description": "Spezialisiert f√ºr Reasoning"},
    ]
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def get_available_models(self) -> list[dict]:
        """Gibt Liste der verf√ºgbaren Modelle zur√ºck."""
        # Perplexity hat keinen /models Endpoint, daher hardcoded
        return self.MODELS
    
    def send_prompt(self, prompt: str, model: str) -> APIResponse:
        """Sendet Prompt an Perplexity API."""
        try:
            response = requests.post(
                f"{self.BASE_URL}/chat/completions",
                headers=self.headers,
                json={
                    "model": model,
                    "messages": [
                        {"role": "user", "content": prompt}
                    ]
                },
                timeout=120  # 2 Minuten Timeout f√ºr lange Analysen
            )
            
            if response.status_code == 200:
                data = response.json()
                content = data["choices"][0]["message"]["content"]
                tokens = data.get("usage", {}).get("total_tokens", 0)
                
                return APIResponse(
                    status=APIStatus.RECEIVED,
                    content=content,
                    model_used=model,
                    provider_used=self.PROVIDER_NAME,
                    tokens_used=tokens
                )
            else:
                return APIResponse(
                    status=APIStatus.ERROR,
                    error_message=f"HTTP {response.status_code}: {response.text}"
                )
                
        except requests.Timeout:
            return APIResponse(
                status=APIStatus.ERROR,
                error_message="Timeout: API antwortet nicht innerhalb von 2 Minuten"
            )
        except Exception as e:
            return APIResponse(
                status=APIStatus.ERROR,
                error_message=str(e)
            )
```

---

## üñºÔ∏è GUI-Erweiterung

### Neues UI-Layout (API-Sektion)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ...bestehende Felder (URL, Meta, Fragen, Preset)...            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ API-MODUS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  [‚úì] API-Automatik aktivieren                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Provider: [Perplexity AI          ‚ñº]                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Modell:   [Sonar Large (Online)   ‚ñº] [‚öôÔ∏è]              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Status:   ‚ö™ Bereit                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  [Generate Prompt]                                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  GENERIERTER PROMPT                                    [Copy]   ‚îÇ
‚îÇ  ...                                                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ANALYSE-ERGEBNIS                    [Status: üü¢ Received]      ‚îÇ
‚îÇ  ...                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Status-Farben

```python
STATUS_COLORS = {
    "idle": ("‚ö™", "#808080", "Bereit"),
    "sending": ("üîµ", "#2196F3", "Sende..."),
    "processing": ("üü°", "#FFC107", "Verarbeite..."),
    "received": ("üü¢", "#4CAF50", "Empfangen"),
    "error": ("üî¥", "#F44336", "Fehler"),
}
```

---

## üìù Settings-Dialog

### Wireframe

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚öôÔ∏è API-Einstellungen                                [X]    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  PROVIDER                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  ‚òë Perplexity AI                                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     API-Key: [************************] [üëÅ] [Test] ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     Status:  ‚úÖ Verbunden (12 Modelle verf√ºgbar)    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚òê OpenRouter                                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     API-Key: [Nicht konfiguriert        ] [üëÅ] [Test]   ‚îÇ
‚îÇ  ‚îÇ     Status:  ‚ö†Ô∏è Kein API-Key                        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  DEFAULT-EINSTELLUNGEN                                      ‚îÇ
‚îÇ  Default-Provider: [Perplexity AI          ‚ñº]              ‚îÇ
‚îÇ  Default-Modell:   [Sonar Large (Online)   ‚ñº]              ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                    [Speichern]  [Abbrechen]          ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Funktionen

- **API-Key anzeigen/verstecken:** üëÅ Button (toggle password visibility)
- **Test-Button:** Validiert den Key durch API-Aufruf (z.B. Models-Liste abrufen)
- **Status-Anzeige:** Zeigt ob Verbindung funktioniert und wie viele Modelle verf√ºgbar

---

## üì¶ Neue Dependencies

Erg√§nzung f√ºr `requirements.txt`:

```txt
# API Integration
requests>=2.31.0
keyring>=24.0.0
```

---

## üöÄ Implementierungsreihenfolge

### Schritt 1: Grundger√ºst (API-Client)
1. `api_client.py` ‚Äì Abstrakte Basis-Klasse
2. `perplexity_client.py` ‚Äì Perplexity-Implementation
3. `api_config.py` ‚Äì Key-Verwaltung mit keyring
4. Manueller Test via Python-Konsole

### Schritt 2: Threading
1. `api_worker.py` ‚Äì QThread-Worker
2. Signal/Slot-Verbindungen testen

### Schritt 3: GUI-Integration
1. API-Sektion in `main_window.py` hinzuf√ºgen
2. Checkbox, Provider-Dropdown, Modell-Dropdown, Status-Label
3. Zahnrad-Button (f√ºhrt zun√§chst zu MessageBox "Coming soon")

### Schritt 4: Settings-Dialog
1. `settings_dialog.py` ‚Äì Vollst√§ndiger Dialog
2. API-Key-Eingabe mit Passwort-Feld
3. Test-Button-Funktionalit√§t
4. Speichern/Laden der Konfiguration

### Schritt 5: LinkedIn-Export-Anpassung
1. `linkedin_formatter.py` erweitern
2. Modell/Provider in Header einf√ºgen wenn API genutzt wurde

### Schritt 6: OpenRouter (parallel zu Perplexity)
1. `openrouter_client.py` ‚Äì Implementation
2. OpenRouter hat `/models` Endpoint ‚Üí dynamische Liste m√∂glich
3. Vorteil: 200+ Modelle, oft g√ºnstigere Preise, kostenlose Testmodelle

---

## üåê OpenRouter API Client

### Endpoint-Dokumentation

- **Base URL:** `https://openrouter.ai/api/v1`
- **Chat Completions:** `POST /chat/completions`
- **Models:** `GET /models` ‚úÖ (dynamische Liste m√∂glich!)

### Besonderheiten

- **200+ Modelle** von verschiedenen Anbietern
- **Kostenlose Testmodelle** bei neuen Releases
- **Dynamische Modell-Liste** via API abrufbar
- **OpenAI-kompatible API** ‚Äì gleiche Struktur wie Perplexity

### Implementation

```python
# src/core/openrouter_client.py
import requests
from .api_client import LLMClient, APIResponse, APIStatus

class OpenRouterClient(LLMClient):
    """OpenRouter API Client ‚Äì Multi-Provider Aggregator."""
    
    BASE_URL = "https://openrouter.ai/api/v1"
    PROVIDER_ID = "openrouter"
    PROVIDER_NAME = "OpenRouter"
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/your-repo",  # Optional aber empfohlen
            "X-Title": "SOMAS Prompt Generator"              # App-Name f√ºr Analytics
        }
    
    def get_available_models(self) -> list[dict]:
        """Holt aktuelle Modell-Liste dynamisch von der API."""
        try:
            response = requests.get(
                f"{self.BASE_URL}/models",
                headers=self.headers,
                timeout=30
            )
            if response.status_code == 200:
                data = response.json()
                # Filter: Nur Chat-f√§hige Modelle
                return [
                    {
                        "id": m["id"],
                        "name": m.get("name", m["id"]),
                        "description": m.get("description", ""),
                        "context_length": m.get("context_length", 0),
                        "pricing": m.get("pricing", {})
                    }
                    for m in data.get("data", [])
                    if "chat" in m.get("id", "").lower() or True  # Alle Chat-Modelle
                ]
        except Exception:
            pass
        # Fallback auf hardcoded Liste
        return self.FALLBACK_MODELS
    
    def send_prompt(self, prompt: str, model: str) -> APIResponse:
        """Sendet Prompt an OpenRouter API."""
        # Gleiche Struktur wie Perplexity (OpenAI-kompatibel)
        ...
```

---

## ‚ö†Ô∏è Wichtige Hinweise

1. **Timeout beachten:** SOMAS-Analysen k√∂nnen lange dauern (60-120 Sekunden)
2. **Fehlerbehandlung:** Netzwerkfehler, Rate Limits, ung√ºltige Keys abfangen
3. **UI-Feedback:** Nutzer muss jederzeit wissen, was passiert
4. **Graceful Degradation:** Ohne API-Key funktioniert die App weiterhin (manueller Modus)
5. **Keine Secrets im Code:** API-Keys niemals hardcoden oder in Git committen

---

## üß™ Test-Szenarios

1. **Happy Path:** API-Modus aktiv ‚Üí Generate Prompt ‚Üí Automatisch Ergebnis
2. **Manueller Override:** API-Modus aktiv, aber User klickt "Copy" und f√ºgt manuell ein
3. **Kein API-Key:** Settings √∂ffnen, "Bitte API-Key eingeben" Hinweis
4. **Falscher API-Key:** Test-Button zeigt Fehler, speichern trotzdem m√∂glich
5. **Timeout:** Nach 120s Timeout-Fehler anzeigen, UI bleibt responsiv
6. **Wechsel w√§hrend Request:** Provider wechseln w√§hrend Request l√§uft ‚Üí alten abbrechen?

---

## üìû Fragen an Thorsten (f√ºr Claude Code)

Falls w√§hrend der Implementierung Unklarheiten auftreten:

1. Soll ein laufender API-Request abgebrochen werden k√∂nnen? (Cancel-Button)
2. Soll die Token-Anzahl/Kosten angezeigt werden?
3. Soll es einen "Retry"-Button bei Fehlern geben?

---

*Erstellt: 2025-01-31 | Version: 1.0*
